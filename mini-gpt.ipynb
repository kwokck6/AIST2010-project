{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "afterpickle_demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc8bG_niqjgm"
      },
      "source": [
        "## Preparations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLhVUJwaqM5t"
      },
      "source": [
        "### Download required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kkk3XW3p_Vl",
        "outputId": "3ca95c80-6f10-4e80-c81b-c762a7008e42"
      },
      "source": [
        "!pip install music21\n",
        "!pip install mido\n",
        "!pip install pretty_midi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: music21 in /usr/local/lib/python3.7/dist-packages (5.5.0)\n",
            "Requirement already satisfied: mido in /usr/local/lib/python3.7/dist-packages (1.2.10)\n",
            "Requirement already satisfied: pretty_midi in /usr/local/lib/python3.7/dist-packages (0.2.9)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pretty_midi) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pretty_midi) (1.15.0)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.7/dist-packages (from pretty_midi) (1.2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iw9iWCXjLhJ"
      },
      "source": [
        "### Import modules and define paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0dfe-nxqbWl"
      },
      "source": [
        "import pretty_midi\n",
        "from music21 import *\n",
        "import numpy as np\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import glob\n",
        "from itertools import groupby\n",
        "import math\n",
        "import pickle\n",
        "import gc\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "mlb.fit([np.arange(128).tolist()])\n",
        "\n",
        "encoded_data_path = '/content/'\n",
        "output_path = '/content/'\n",
        "\n",
        "batch_size = 32\n",
        "sequence_length = 600\n",
        "generate_sample_every_ep = 100\n",
        "\n",
        "maxlen = sequence_length  # Max sequence size\n",
        "embed_dim = 128  # Embedding size for each token\n",
        "num_heads = 4  # Number of attention heads\n",
        "feed_forward_dim = 128  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "combi_to_int_pickle = 'combi_to_int.pickle'\n",
        "int_to_combi_pickle = 'int_to_combi.pickle'\n",
        "vocab_pickle = 'vocab.pickle'\n",
        "\n",
        "vocab_size = 7184  # classical = 7184; jazz = 40000\n",
        "unk_tag_str = '<UNK>'\n",
        "unk_tag_idx = 0\n",
        "pad_tag_str = ''\n",
        "pad_tag_idx = 1\n",
        "\n",
        "# !unzip /content/classical_data.zip\n",
        "# !unzip /content/jazz_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs_n6K1gyPXT"
      },
      "source": [
        "### Import variables from pickle\n",
        "If you did not manually process and tokenise data yourself, importing is necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5AeJns-yPXT"
      },
      "source": [
        "with open('/content/longer_classical_combi_to_int.pickle', 'rb') as f:\n",
        "    combi_to_int = pickle.load(f)\n",
        "    \n",
        "with open('/content/longer_classical_all_song_tokenised.pickle', 'rb') as f:\n",
        "    all_song_tokenised = pickle.load(f)\n",
        "\n",
        "with open('/content/longer_classical_int_to_combi.pickle', 'rb') as f:\n",
        "    int_to_combi = pickle.load(f)\n",
        "    \n",
        "with open('/content/longer_classical_vocab.pickle', 'rb') as f:\n",
        "    vocab = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyE_rYnJqUjo"
      },
      "source": [
        "## Transformer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZOK3emyh0D0"
      },
      "source": [
        "### Embedding Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17Qdsb5Ih4Vk"
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.maxlen = maxlen\n",
        "        self.maximum_position_encoding = 10000\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'vocab_size': self.vocab_size,\n",
        "            'embed_dim': self.embed_dim,\n",
        "            'maxlen': self.maxlen,\n",
        "        })\n",
        "        return config\n",
        "    \n",
        "    def get_angles(self, pos, i, d_model):\n",
        "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "        return pos * angle_rates\n",
        "    \n",
        "    def positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis],\n",
        "                              np.arange(d_model)[np.newaxis, :],\n",
        "                              d_model)\n",
        "\n",
        "        # apply sin to even indices in the array; 2i\n",
        "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "        # apply cos to odd indices in the array; 2i+1\n",
        "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "        \n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        pos_encoding = self.positional_encoding(self.maximum_position_encoding, self.embed_dim)\n",
        "        x = self.token_emb(x)\n",
        "        return x + pos_encoding[:, :maxlen, :]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh3RhUvE8cKt"
      },
      "source": [
        "### Self-attention with causal masking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfaLa27o9AgN"
      },
      "source": [
        "class MultiHeadSelfAttention(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        #defining no of nodes/dim for each layer\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(\n",
        "                f'embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}'\n",
        "            )\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = layers.Dense(embed_dim)\n",
        "        self.key_dense = layers.Dense(embed_dim)\n",
        "        self.value_dense = layers.Dense(embed_dim)\n",
        "        self.combine_heads = layers.Dense(embed_dim)\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'embed_dim': self.embed_dim,\n",
        "            'num_heads': self.num_heads,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @staticmethod\n",
        "    def causal_attention_mask(n_dest, n_src, dtype):\n",
        "        \"\"\"\n",
        "        1's in the lower triangle, counting from the lower right corner.\n",
        "        \"\"\"\n",
        "        i = tf.range(n_dest)[:, None]\n",
        "        j = tf.range(n_src)\n",
        "        m = i >= j - n_src + n_dest\n",
        "        return tf.cast(m, dtype)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "\n",
        "        # prevent information flow from future tokens\n",
        "        shape = tf.shape(scaled_score)\n",
        "        dim_dest, dim_src = shape[2], shape[3]\n",
        "        attention_mask = self.causal_attention_mask(\n",
        "            dim_dest, dim_src, scaled_score.dtype\n",
        "        )\n",
        "        attention_mask = tf.reshape(attention_mask, [1, 1, dim_dest, dim_src])\n",
        "        scaled_score = scaled_score * attention_mask - 1e4 * (1 - attention_mask)\n",
        "\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        \n",
        "        # each of size (batch_size, seq_len, embed_dim)\n",
        "        query = self.query_dense(inputs)  \n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "        \n",
        "        # each of size (batch_size, num_heads, seq_len, projection_dim)\n",
        "        query = self.separate_heads(query, batch_size)  \n",
        "        key = self.separate_heads(key, batch_size)\n",
        "        value = self.separate_heads(value, batch_size)\n",
        "        \n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        # attention: (batch_size, seq_len, num_heads, projection_dim)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        # concat_attention: (batch_size, seq_len, embed_dim)\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))  \n",
        "        output = self.combine_heads(concat_attention)  # (batch_size, seq_len, embed_dim)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNXWdP8DgnUK"
      },
      "source": [
        "### Transformer block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDvR-OPdgqbu"
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.ff_dim = ff_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "        \n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = keras.Sequential([\n",
        "            layers.Dense(ff_dim, activation='relu'),\n",
        "            layers.Dense(embed_dim)\n",
        "        ])\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(dropout_rate)\n",
        "        self.dropout2 = layers.Dropout(dropout_rate)\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'embed_dim': self.embed_dim,\n",
        "            'num_heads': self.num_heads,\n",
        "            'ff_dim': self.ff_dim,\n",
        "            'dropout_rate': self.dropout_rate,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attention_output = self.att(inputs)\n",
        "        attention_output = self.dropout1(attention_output)\n",
        "        out1 = self.layernorm1(inputs + attention_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wH-kaFSjC7G"
      },
      "source": [
        "### Create a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I0tMJJBjGNd"
      },
      "source": [
        "train_loss = []\n",
        "val_loss = []\n",
        "\n",
        "def create_model():\n",
        "    inputs = layers.Input(shape=(maxlen,), dtype=tf.int32)\n",
        "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "    x = embedding_layer(inputs)\n",
        "    transformer_block1 = TransformerBlock(embed_dim, num_heads, feed_forward_dim, dropout_rate = 0.25)\n",
        "    transformer_block2 = TransformerBlock(embed_dim, num_heads, feed_forward_dim, dropout_rate = 0.25)\n",
        "    transformer_block3 = TransformerBlock(embed_dim, num_heads, feed_forward_dim, dropout_rate = 0.25)\n",
        "    x = transformer_block1(x)\n",
        "    x = transformer_block2(x)\n",
        "    x = transformer_block3(x)\n",
        "    outputs = layers.Dense(vocab_size)(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=[outputs, x])\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    # No loss and optimization based on word embeddings from transformer block\n",
        "    model.compile('adam', loss=[loss_fn, None])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4CxlkIjyPXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9706fbbf-f52a-442c-f2cc-52f8acc19233"
      },
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 600)]             0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, 600, 128)         919552    \n",
            " g (TokenAndPositionEmbeddin                                     \n",
            " g)                                                              \n",
            "                                                                 \n",
            " transformer_block (Transfor  (None, 600, 128)         99584     \n",
            " merBlock)                                                       \n",
            "                                                                 \n",
            " transformer_block_1 (Transf  (None, 600, 128)         99584     \n",
            " ormerBlock)                                                     \n",
            "                                                                 \n",
            " transformer_block_2 (Transf  (None, 600, 128)         99584     \n",
            " ormerBlock)                                                     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 600, 7184)         926736    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,145,040\n",
            "Trainable params: 2,145,040\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHum1tMWyPXY"
      },
      "source": [
        "## Generator\n",
        "A custom generator to input one random sequence from each song to train. (Instead of the old method of one shot loading all iterative sequence to the model to train, referenced from MusicTransformer)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX8qm-yGyPXY"
      },
      "source": [
        "class Generator(keras.utils.Sequence) :\n",
        "    def __init__(self, all_song_tokenised, batch_size, sequence_length, \n",
        "                 val_split=0, shuffle=True) :\n",
        "        self.all_song_tokenised = all_song_tokenised\n",
        "        self.pad_tag_idx = 1\n",
        "        self.sequence_length = sequence_length\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.val_split = val_split\n",
        "        if(self.val_split != 0):\n",
        "            self.all_song_tokenised = random.choices(\n",
        "                self.all_song_tokenised, k=int(self.val_split*len(self.all_song_tokenised)))\n",
        "            self.batch_size = len(self.all_song_tokenised)\n",
        "        self.on_epoch_end()\n",
        "    \n",
        "    def __len__(self) :\n",
        "        return int(np.ceil(len(self.all_song_tokenised)/ self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.all_song_tokenised)\n",
        "  \n",
        "    def __getitem__(self, idx) :\n",
        "        batch_x = np.empty((0, self.sequence_length), float)\n",
        "        batch_y = np.empty((0, self.sequence_length), float)\n",
        "        for i in range(self.batch_size):\n",
        "            if idx * self.batch_size + i == len(self.all_song_tokenised) - 1:\n",
        "                return batch_x, batch_y\n",
        "            song = self.all_song_tokenised[idx*self.batch_size + i]\n",
        "            start_idx = random.randint(0,len(song) - self.sequence_length / 2)\n",
        "            seq = song[start_idx: start_idx + self.sequence_length + 1]\n",
        "            x = seq[:-1]\n",
        "            y = seq[1:]\n",
        "            # padding if needed\n",
        "            if len(y) < self.sequence_length:\n",
        "                no_of_pad = self.sequence_length - len(y)\n",
        "                x = np.append(x, [self.pad_tag_idx]*no_of_pad, axis = 0)\n",
        "                y = np.append(y, [self.pad_tag_idx]*no_of_pad, axis = 0)\n",
        "            \n",
        "            batch_x = np.append(batch_x, [x], axis = 0)\n",
        "            batch_y = np.append(batch_y, [y], axis = 0)\n",
        "            \n",
        "        return batch_x, batch_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97AURazVyPXY"
      },
      "source": [
        "## Sequence Generator Callback\n",
        "It shows an instance of how the model behave once every specified epochs. Fixed seed sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tun3NPpVyPXY"
      },
      "source": [
        "class GeneratorCallback(keras.callbacks.Callback):\n",
        "    '''Callback to generate text from trained model.\n",
        "    1. Feed some starting prompt to the model\n",
        "    2. Predict probabilities for next token\n",
        "    3. Sample next token and add it to the next input\n",
        "\n",
        "    # Arguments\n",
        "        max_tokens: Integer, the number of tokens to be generated after prompt.\n",
        "        start_tokens: List of integers, the token indices for the starting prompt.\n",
        "        index_to_word: List of strings, obtained from TextVectorization layer.\n",
        "        top_k: Integer, sample from the `top_k` token predictions.\n",
        "        print_every: Integer, print after this many epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, max_tokens, start_tokens, top_k=10, print_every=5):\n",
        "        self.max_tokens = max_tokens\n",
        "        self.start_tokens = start_tokens\n",
        "        self.print_every = print_every\n",
        "        self.k = top_k\n",
        "\n",
        "    def sample_from(self, logits):\n",
        "        logits, indices = tf.math.top_k(logits, k=self.k, sorted=True)\n",
        "        indices = np.asarray(indices).astype('int32')\n",
        "        preds = keras.activations.softmax(tf.expand_dims(logits, 0))[0]\n",
        "        preds = np.asarray(preds).astype('float32')\n",
        "        return np.random.choice(indices, p=preds)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        start_tokens = [_ for _ in self.start_tokens]\n",
        "        if (epoch + 1) % self.print_every != 0:\n",
        "            return\n",
        "        num_tokens_generated = 0\n",
        "        tokens_generated = []\n",
        "        while num_tokens_generated <= self.max_tokens:\n",
        "            x = start_tokens[-sequence_length:]\n",
        "            pad_len = maxlen - len(start_tokens)\n",
        "            sample_index = -1\n",
        "            if pad_len > 0:\n",
        "                x = start_tokens + [0] * pad_len\n",
        "                sample_index = len(start_tokens) - 1\n",
        "            \n",
        "            x = np.array([x])\n",
        "            y, _ = self.model.predict(x)\n",
        "            sample_token = self.sample_from(y[0][sample_index])\n",
        "            tokens_generated.append(sample_token)\n",
        "            start_tokens.append(sample_token)\n",
        "            num_tokens_generated = len(tokens_generated)\n",
        "\n",
        "        print(f'Last 40 tokens of starting token:\\n{self.start_tokens[-50:]}\\n')\n",
        "        print(f'Generated token:\\n{tokens_generated}\\n')\n",
        "\n",
        "start_tokens = all_song_tokenised[1][:sequence_length - 200]\n",
        "num_tokens_generated = 80\n",
        "gen_callback = GeneratorCallback(num_tokens_generated, start_tokens, print_every=generate_sample_every_ep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC841L89yPXZ"
      },
      "source": [
        "# Train data (by loading weight or training from the start)\n",
        "Note: Even with GPU, training can take as long as 2.5 hours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afVVjFlQKjAC"
      },
      "source": [
        "method = 'load'  # 'load' or 'train': training can take as long as 2.5 hours!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6IJor4myPXZ"
      },
      "source": [
        "if method == 'load':\n",
        "    model.load_weights('/content/classic_music-gen-weight.hdf5')\n",
        "elif method == 'train':\n",
        "    epochs = 1500\n",
        "    batchsize = 64\n",
        "    output_path = f'/content/output/classic_MuGenTransformer_v3_{epochs}{batchsize}{int(time.time())}_16v2f/'\n",
        "\n",
        "    training_batch_generator = Generator(all_song_tokenised, batchsize, sequence_length)\n",
        "    validation_batch_generator = Generator(all_song_tokenised, batchsize, sequence_length, val_split=0.1)\n",
        "\n",
        "    if not os.path.exists(output_path):\n",
        "        os.mkdir(output_path)\n",
        "\n",
        "    weight_path = output_path + 'music-gen-weight.hdf5'\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "        weight_path,\n",
        "        monitor='loss',\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    callbacks_list = [checkpoint,gen_callback]\n",
        "\n",
        "    history = model.fit(x=training_batch_generator, callbacks=callbacks_list, \n",
        "                        epochs=epochs, verbose=1, \n",
        "                        validation_data=validation_batch_generator)\n",
        "\n",
        "    train_loss += history.history['loss']\n",
        "    val_loss += history.history['val_loss']\n",
        "\n",
        "    plt.plot(train_loss)\n",
        "    plt.plot(val_loss)\n",
        "    plt.title('model train vs validation loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'validation_loss'], loc='upper right')\n",
        "    plt.savefig(output_path + 'loss.png')\n",
        "    plt.show()\n",
        "    print('Result stored in {}'.format(output_path))\n",
        "else:\n",
        "    raise ValueError('method must be one of \"load\" or \"train\"')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBRLSvx7yPXZ"
      },
      "source": [
        "## Inference\n",
        "We take a random sequence from a random song as the input. \n",
        "Then we will pass this input and predict the next notes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyfePWuDyPXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa5c68a0-af2d-4a08-de68-e57591b97420"
      },
      "source": [
        "seed_len = 100\n",
        "num_note_to_gen = 1000\n",
        "\n",
        "song_idx = random.randint(0, len(all_song_tokenised)-1)\n",
        "seq_start_at = random.randint(0, abs(len(all_song_tokenised[song_idx]) - sequence_length))   \n",
        "start_tokens = all_song_tokenised[song_idx][seq_start_at:seq_start_at + seed_len].tolist()\n",
        "while start_tokens == [()] * sequence_length:\n",
        "    print('Got all zeros, rerolling')\n",
        "    song_idx = random.randint(0, len(all_song_tokenised) - 1)\n",
        "    seq_start_at = random.randint(0,len(all_song_tokenised[song_idx])-sequence_length)   \n",
        "    start_tokens = all_song_tokenised[song_idx][seq_start_at:seq_start_at + sequence_length].tolist()\n",
        "    \n",
        "ori = start_tokens.copy()\n",
        "backup = ori.copy()\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "    '''Compute softmax values for each sets of scores in x.'''\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "\n",
        "def sample_from(logits, k):\n",
        "    logits, indices = tf.math.top_k(logits, k= k, sorted=True)\n",
        "    indices = np.asarray(indices).astype('int32')\n",
        "    preds = np.asarray(logits).astype('float32')\n",
        "    if(unk_tag_idx in indices):\n",
        "        unk_tag_position = np.where(indices == unk_tag_idx)[0].item()\n",
        "        indices = np.delete(indices, unk_tag_position)\n",
        "        preds = np.delete(preds, unk_tag_position)\n",
        "    preds = softmax(preds)\n",
        "    return np.random.choice(indices, p=preds)\n",
        "\n",
        "def convertToRoll(seq_list):\n",
        "    seq_list = [int_to_combi[i] for i in seq_list]\n",
        "    roll = mlb.transform(seq_list)\n",
        "    print(seq_list)\n",
        "    return roll\n",
        "\n",
        "\n",
        "k = 10\n",
        "tokens_generated = []\n",
        "num_tokens_generated = 0\n",
        "\n",
        "while num_tokens_generated <= num_note_to_gen:\n",
        "    x = start_tokens[-sequence_length:]\n",
        "    pad_len = maxlen - len(start_tokens)\n",
        "    sample_index = -1\n",
        "    if pad_len > 0:\n",
        "        x = start_tokens + [0] * pad_len\n",
        "        sample_index = len(start_tokens) - 1\n",
        "    \n",
        "    x = np.array([x])\n",
        "    y, _ = model.predict(x)\n",
        "    sample_token = sample_from(y[0][sample_index], 10)\n",
        "    tokens_generated.append(sample_token)\n",
        "    start_tokens.append(sample_token)\n",
        "    num_tokens_generated = len(tokens_generated)\n",
        "    if num_tokens_generated % 50 == 0:\n",
        "        print(f'Generated {num_tokens_generated} notes...')\n",
        "    \n",
        "piano_roll = convertToRoll(start_tokens)\n",
        "print('-------------------------------------------')\n",
        "ori = convertToRoll(ori)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 50 notes...\n",
            "Generated 100 notes...\n",
            "Generated 150 notes...\n",
            "Generated 200 notes...\n",
            "Generated 250 notes...\n",
            "Generated 300 notes...\n",
            "Generated 350 notes...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7qwLjrnyPXZ"
      },
      "source": [
        "def piano_roll_to_pretty_midi(piano_roll_in, fs, program=0, velocity = 64):\n",
        "    '''Convert a Piano Roll array into a PrettyMidi object\n",
        "     with a single instrument.\n",
        "    Parameters\n",
        "    ----------\n",
        "    piano_roll : np.ndarray, shape=(128,frames), dtype=int\n",
        "        Piano roll of one instrument\n",
        "    fs : int\n",
        "        Sampling frequency of the columns, i.e. each column is spaced apart\n",
        "        by ``1./fs`` seconds.\n",
        "    program : int\n",
        "        The program number of the instrument.\n",
        "    Returns\n",
        "    -------\n",
        "    midi_object : pretty_midi.PrettyMIDI\n",
        "        A pretty_midi.PrettyMIDI class instance describing\n",
        "        the piano roll.\n",
        "    '''\n",
        "    piano_roll = np.where(piano_roll_in == 1, 64, 0)\n",
        "    notes, frames = piano_roll.shape\n",
        "    pm = pretty_midi.PrettyMIDI(initial_tempo=100.0)\n",
        "    instrument = pretty_midi.Instrument(program=program)\n",
        "\n",
        "    # pad 1 column of zeros so we can acknowledge inital and ending events\n",
        "    piano_roll = np.pad(piano_roll, [(0, 0), (1, 1)], 'constant')\n",
        "    print(piano_roll.shape)\n",
        "    \n",
        "    # use changes in velocities to find note on / note off events\n",
        "    velocity_changes = np.nonzero(np.diff(piano_roll).T)\n",
        "\n",
        "    # keep track on velocities and note on times\n",
        "    prev_velocities = np.zeros(notes, dtype=int)\n",
        "    note_on_time = np.zeros(notes)\n",
        "\n",
        "    for time, note in zip(*velocity_changes):\n",
        "        # use time + 1 because of padding above\n",
        "        velocity = piano_roll[note, time + 1]\n",
        "        time = time / fs\n",
        "        if velocity > 0:\n",
        "            if prev_velocities[note] == 0:\n",
        "                note_on_time[note] = time\n",
        "                prev_velocities[note] = velocity\n",
        "        else:\n",
        "            pm_note = pretty_midi.Note(\n",
        "                velocity=prev_velocities[note],\n",
        "                pitch=note,\n",
        "                start=note_on_time[note],\n",
        "                end=time)\n",
        "            instrument.notes.append(pm_note)\n",
        "            prev_velocities[note] = 0\n",
        "    pm.instruments.append(instrument)\n",
        "    return pm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiZRHupPyPXa"
      },
      "source": [
        "## Export as MIDI\n",
        "Save the inference result to output folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQizTKemyPXa"
      },
      "source": [
        "bpm = 100\n",
        "fs = 1 / ((60 / bpm) /4)\n",
        "name = 'random8_200'\n",
        "mid_out = piano_roll_to_pretty_midi(piano_roll.T, fs=fs)\n",
        "mid_ori = piano_roll_to_pretty_midi(ori.T, fs=fs)\n",
        "midi_out_path = output_path + f'gpt-v3-id-{name}.mid'\n",
        "if midi_out_path is not None:\n",
        "    mid_out.write(midi_out_path)\n",
        "        \n",
        "midi_ori_path = output_path + f'ori-gpt-v3-id-{name}.mid'\n",
        "if midi_ori_path is not None:\n",
        "    mid_ori.write(midi_ori_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLRz2K9ByPXa"
      },
      "source": [
        "Save full length of seed song for reference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO0QmX3SZqCF"
      },
      "source": [
        "from google.colab import files\n",
        "# if need zip\n",
        "# !zip -r /content/output.zip /content/output\n",
        "files.download('/content/gpt-v3-id-random8_200.mid')\n",
        "# files.download('/content/ori-gpt-v3-id-random8_200.mid')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}